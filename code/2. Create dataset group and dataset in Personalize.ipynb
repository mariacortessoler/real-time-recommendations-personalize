{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset group and dataset in Personalize\n",
    "This notebook creates the Amazon Personalize interactions dataset and resources for the Amazon videos recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='contents' />\n",
    "\n",
    "## Content Table\n",
    "\n",
    "1. [Loading libraries and data](#loading)\n",
    "2. [Setting permissions](#permissions)\n",
    "3. [Create schemas](#schema)\n",
    "4. [Create dataset groups and datasets within](#dataset)\n",
    "5. [Create an import job for each of the datasets](#import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading' />\n",
    "\n",
    "## Loading libraries and data\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkride-mfcs-aiml\n",
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "import time\n",
    "import sagemaker\n",
    "\n",
    "account_num = '<YOUR_ACCOUNT_NUMBER>'\n",
    "bucket   = '<YOUR_BUCKET_NAME>'\n",
    "print(bucket)\n",
    "prefix   = 'tidy_data'\n",
    "region   = boto3.Session().region_name\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set a name for the dataset group\n",
    "dataset_group_name = 'video-dataset-group'\n",
    "#Set a name for the interactions schema\n",
    "VIDEO_INTERACTION_SCHEMA_NAME = 'video-interactions-schema'\n",
    "VIDEO_INTERACTION_SCHEMA_ARN  = 'arn:aws:personalize:{}:{}:schema/'.format(region, account_num) + \\\n",
    "                                VIDEO_INTERACTION_SCHEMA_NAME\n",
    "#Input name of the data on interactions\n",
    "interactions_filename = 'movies-interactions.csv'\n",
    "#Interactions dataset name in Personalize\n",
    "interactions_dataset_name='video-interactions'\n",
    "\n",
    "MAX_WAIT_TIME = time.time() + 60*60 # 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='permissions' />\n",
    "\n",
    "## Setting permissions\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up IAM role and allow Personalize to access your bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**S3 Bucket Permissions for Personalize Access**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Personalize needs to be able to read the contents of the S3 bucket. So add a bucket policy which allows that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allow_bucket_access():\n",
    "    s3 = boto3.client('s3')\n",
    "    policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"personalize.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": [\n",
    "                    \"s3:GetObject\",\n",
    "                    \"s3:ListBucket\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    \"arn:aws:s3:::{}\".format(bucket),\n",
    "                    \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    s3.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "allow_bucket_access()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an IAM Role that gives Amazon Personalize permissions to access your S3 bucket.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Personalize needs the ability to assume roles in AWS in order to have the permissions to execute certain tasks. We create an IAM role and attach the required policies to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_personalize_role():\n",
    "    iam = boto3.client('iam')\n",
    "\n",
    "    role_name = 'PersonalizeS3Role'\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "              \"Effect\": \"Allow\",\n",
    "              \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "              },\n",
    "              \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print('Creating role: {}...'.format(role_name))\n",
    "        create_role_response = iam.create_role(\n",
    "            RoleName = role_name,\n",
    "            AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print('role creation failed. Likely already existed.')\n",
    "\n",
    "    print('Attaching Personalize full access policy...')\n",
    "    pers_policy_arn = 'arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess'\n",
    "    iam.attach_role_policy(\n",
    "        RoleName  = role_name,\n",
    "        PolicyArn = pers_policy_arn\n",
    "    )\n",
    "    print('Attaching S3 read-only access policy...')\n",
    "    s3_policy_arn = 'arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess'\n",
    "    iam.attach_role_policy(\n",
    "        RoleName  = role_name,\n",
    "        PolicyArn = s3_policy_arn\n",
    "    )\n",
    "\n",
    "    print('Waiting for policy attachment to propagate...')\n",
    "    time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "    role_arn = 'arn:aws:iam::{}:role/{}'.format(account_num, role_name)\n",
    "    return role_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating role: PersonalizeS3Role...\n",
      "role creation failed. Likely already existed.\n",
      "Attaching Personalize full access policy...\n",
      "Attaching S3 read-only access policy...\n",
      "Waiting for policy attachment to propagate...\n",
      "arn:aws:iam::386102487792:role/PersonalizeS3Role\n"
     ]
    }
   ],
   "source": [
    "role_arn = create_personalize_role()\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='schema' />\n",
    "\n",
    "## Creating schemas\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the interactions schema if it is not in place already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a schema to tell Amazon Personalize what type of dataset to upload. in this case we will use information on the User ID, the item ID, the timestamp, event rating, whether the purchase was verified or not, and event type (always \"review\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema arn:aws:personalize:us-east-1:386102487792:schema/video-interactions-schema did not exist, creating it...\n",
      "{\n",
      "  \"schemaArn\": \"arn:aws:personalize:us-east-1:386102487792:schema/video-interactions-schema\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"ac6e4c32-5506-4ec4-96b0-0fb5155516f6\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Thu, 30 Jul 2020 21:53:57 GMT\",\n",
      "      \"x-amzn-requestid\": \"ac6e4c32-5506-4ec4-96b0-0fb5155516f6\",\n",
      "      \"content-length\": \"91\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # first see if the schema is already in place\n",
    "    arn = VIDEO_INTERACTION_SCHEMA_ARN\n",
    "    response = personalize.describe_schema(schemaArn=arn)\n",
    "    interactions_schema_arn = response['schema']['schemaArn']\n",
    "    print(interactions_schema_arn)\n",
    "except Exception as e:\n",
    "    print('Schema {} did not exist, creating it...'.format(arn))\n",
    "    schema = {\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"Interactions\",\n",
    "        \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"name\": \"USER_ID\",\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"ITEM_ID\",\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"TIMESTAMP\",\n",
    "                \"type\": \"long\"\n",
    "            },\n",
    "            { \n",
    "                \"name\": \"EVENT_RATING\",\n",
    "                \"type\": \"float\"\n",
    "            },\n",
    "            { \n",
    "                \"name\": \"EVENT_VERIFIED_PURCHASE\",\n",
    "                \"type\": \"string\",\n",
    "                \"categorical\": True\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"EVENT_TYPE\",\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        ],\n",
    "        \"version\": \"1.0\"\n",
    "    }\n",
    "\n",
    "    create_schema_response = personalize.create_schema(\n",
    "        name   = VIDEO_INTERACTION_SCHEMA_NAME,\n",
    "        schema = json.dumps(schema)\n",
    "    )\n",
    "\n",
    "    interactions_schema_arn = create_schema_response['schemaArn']\n",
    "    print(json.dumps(create_schema_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dataset' />\n",
    "\n",
    "## Create a dataset group and the datasets within it\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information stored within dataset groups has no impact on any other dataset group or models created before. This allows to run many experiments. Before importing the data prepared earlier, there needs to be a dataset group and a dataset added to it that handles the interactions.\n",
    "\n",
    "Dataset groups can house the following types of information:\n",
    "\n",
    "- User-item-interactions\n",
    "- Event streams (real-time interactions)\n",
    "- User metadata\n",
    "- Item metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating new dataset group video-dataset-group\n",
      "{\n",
      "  \"datasetGroupArn\": \"arn:aws:personalize:us-east-1:386102487792:dataset-group/video-dataset-group\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"26f68de1-3b78-48bd-a84f-1eb4056cb6f2\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Thu, 30 Jul 2020 22:04:52 GMT\",\n",
      "      \"x-amzn-requestid\": \"26f68de1-3b78-48bd-a84f-1eb4056cb6f2\",\n",
      "      \"content-length\": \"98\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('\\nCreating new dataset group {}'.format(dataset_group_name))\n",
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = dataset_group_name\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use the dataset group, it must be active. This can take a minute or two. Wait the cell below to show the ACTIVE status. It checks the status of the dataset group every second, up to a maximum of 1 hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetGroup: CREATE PENDING\n",
      "DatasetGroup: ACTIVE\n"
     ]
    }
   ],
   "source": [
    "max_time = time.time() + MAX_WAIT_TIME\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response['datasetGroup']['status']\n",
    "    print('DatasetGroup: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the interactions dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the interactions dataset with the name defined at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetArn\": \"arn:aws:personalize:us-east-1:386102487792:dataset/video-dataset-group/INTERACTIONS\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"3bdc696e-b4ba-4609-8269-1503f2a23a0c\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Thu, 30 Jul 2020 22:05:56 GMT\",\n",
      "      \"x-amzn-requestid\": \"3bdc696e-b4ba-4609-8269-1503f2a23a0c\",\n",
      "      \"content-length\": \"100\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataset_type = 'INTERACTIONS'\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = interactions_dataset_name,\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = interactions_schema_arn\n",
    ")\n",
    "\n",
    "interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:personalize:us-east-1:386102487792:schema/video-interactions-schema\n",
      "arn:aws:personalize:us-east-1:386102487792:dataset-group/video-dataset-group\n"
     ]
    }
   ],
   "source": [
    "print(interactions_schema_arn)\n",
    "print(dataset_group_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import' />\n",
    "\n",
    "## Create an import job for each of the datasets\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we execute an import job that will load the data from the S3 bucket into the Amazon Personalize dataset.\n",
    "We create and run the dataset import job using the CreateDatasetImportJob API, specifying the datasetGroupArn and set the dataLocation to the S3 bucket where we stored the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"datasetImportJobArn\": \"arn:aws:personalize:us-east-1:386102487792:dataset-import-job/video-dataset-group-interactions-import\",\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"00d48c50-f70b-4421-9353-517a2572448e\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"content-type\": \"application/x-amz-json-1.1\",\n",
      "      \"date\": \"Thu, 30 Jul 2020 22:05:56 GMT\",\n",
      "      \"x-amzn-requestid\": \"00d48c50-f70b-4421-9353-517a2572448e\",\n",
      "      \"content-length\": \"127\",\n",
      "      \"connection\": \"keep-alive\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = '{}-interactions-import'.format(dataset_group_name),\n",
    "    datasetArn = interactions_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}/{}\".format(bucket, prefix, interactions_filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "interactions_dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for the dataset import jobs to complete\n",
    "Wait for Dataset Import Jobs Active Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for INTERACTIONS data import to complete...\n",
      "DatasetImportJob: CREATE PENDING\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: CREATE IN_PROGRESS\n",
      "DatasetImportJob: ACTIVE\n",
      "CPU times: user 119 ms, sys: 14.9 ms, total: 134 ms\n",
      "Wall time: 19min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Waiting for INTERACTIONS data import to complete...')\n",
    "max_time = time.time() + MAX_WAIT_TIME\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = interactions_dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response['datasetImportJob']['status']\n",
    "    print('DatasetImportJob: {}'.format(status))\n",
    "    \n",
    "    if status == 'ACTIVE' or status == 'CREATE FAILED':\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "    if status == 'ACTIVE':\n",
    "        print('INTERACTIONS dataset is ACTIVE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Just in case we made a mistake or need to clean the resources, we can delete them as follows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_solution(s):\n",
    "    try:\n",
    "        personalize.delete_solution(solutionArn = s)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_dataset(d):\n",
    "    try:\n",
    "        print('Deleting {}'.format(d))\n",
    "        personalize.delete_dataset(datasetArn=d)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_schema(s):\n",
    "    try:\n",
    "        print('Deleting {}'.format(s))\n",
    "        personalize.delete_schema(schemaArn=s)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_solution('arn:aws:personalize:us-east-1:386102487792:solution/video-hrnn-metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting arn:aws:personalize:us-east-1:386102487792:dataset/video-dataset-group/INTERACTIONS\n"
     ]
    }
   ],
   "source": [
    "# delete_dataset(\"arn:aws:personalize:us-east-1:386102487792:dataset/video-dataset-group/INTERACTIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting arn:aws:personalize:us-east-1:386102487792:schema/video-interactions-schema\n"
     ]
    }
   ],
   "source": [
    "# delete_schema(VIDEO_INTERACTION_SCHEMA_ARN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
